{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\longyu3\\AppData\\Local\\Temp\\ipykernel_21172\\516987749.py:14: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  chain_one = LLMChain(\n",
      "C:\\Users\\longyu3\\AppData\\Local\\Temp\\ipykernel_21172\\516987749.py:59: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  overall_chain(content)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new SequentialChain chain...\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mHuman: 把下面内容翻译成中文：\n",
      "\n",
      "\n",
      "Apache Spark is a unified analytics engine for large-scale data processing. It provides high-level APIs in Java, Scala, Python and R, and an optimized engine that supports general execution graphs. It also supports a rich set of higher-level tools including Spark SQL for SQL and structured data processing, pandas API on Spark for pandas workloads, MLlib for machine learning, GraphX for graph processing, and Structured Streaming for incremental computation and stream processing.\n",
      "\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mHuman: 用一句话总结下面内容:\n",
      "\n",
      "Apache Spark 是一款用于大规模数据处理的统一分析引擎。它提供Java、Scala、Python和R的高级API，以及支持通用执行图的优化引擎。该引擎还包含一系列丰富的上层工具：支持SQL与结构化数据处理的Spark SQL、面向pandas工作负载的Spark版pandas API、机器学习库MLlib、图计算工具GraphX，以及用于增量计算与流处理的Structured Streaming组件。\n",
      "\n",
      "（翻译说明：\n",
      "1. 采用技术文档专业用语，如\"unified analytics engine\"译为\"统一分析引擎\"\n",
      "2. 保留专业术语原名+中文解释的格式，如\"pandas API on Spark\"处理为\"Spark版pandas API\"\n",
      "3. 将英文长句拆分为符合中文阅读习惯的短句结构\n",
      "4. 使用\"该引擎\"替代重复的主语，保持行文流畅\n",
      "5. 技术组件名称如MLlib/GraphX等保留原名不翻译，符合行业惯例\n",
      "6. \"incremental computation\"译为专业术语\"增量计算\"而非字面翻译）\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mHuman: 下面内容是什么语言:\n",
      "\n",
      "Apache Spark是一个支持多语言API和多种数据处理模式（SQL、机器学习、图计算、流处理等）的统一大数据分析引擎。  \n",
      "\n",
      "（说明：  \n",
      "1. 核心提炼为\"统一大数据分析引擎\"突出定位  \n",
      "2. \"多语言API\"概括Java/Scala/Python/R支持  \n",
      "3. \"多种数据处理模式\"整合所有上层组件特性  \n",
      "4. 保留技术文档简洁性，省略具体组件名称  \n",
      "5. 用括号补充关键特性，符合中文技术文档表述习惯）\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mHuman: 请使用指定的语言对以下内容进行回复:\n",
      "\n",
      "内容:Apache Spark是一个支持多语言API和多种数据处理模式（SQL、机器学习、图计算、流处理等）的统一大数据分析引擎。  \n",
      "\n",
      "（说明：  \n",
      "1. 核心提炼为\"统一大数据分析引擎\"突出定位  \n",
      "2. \"多语言API\"概括Java/Scala/Python/R支持  \n",
      "3. \"多种数据处理模式\"整合所有上层组件特性  \n",
      "4. 保留技术文档简洁性，省略具体组件名称  \n",
      "5. 用括号补充关键特性，符合中文技术文档表述习惯）\n",
      "\n",
      "语言:这段内容是**中文技术文档**，具有以下典型特征：\n",
      "\n",
      "1. **语言形式**：  \n",
      "   - 主体为简体中文，符合技术文档的简洁表述风格（如使用术语\"API\"\"SQL\"\"流处理\"等）。  \n",
      "   - 括号内的补充说明采用中文技术文档常见的注释格式，用于解释内容提炼逻辑。\n",
      "\n",
      "2. **内容特点**：  \n",
      "   - 对Apache Spark的技术定位进行概括性描述（\"统一大数据分析引擎\"）。  \n",
      "   - 通过中文特有的概括性表达（如\"多语言API\"统称四种语言支持）简化技术细节。  \n",
      "   - 符合中文技术写作习惯的\"总分结构\"：先总结核心定位，再用括号补充说明提炼依据。\n",
      "\n",
      "3. **文化适配**：  \n",
      "   - 主动省略具体组件名称（如MLlib、GraphX），符合中文文档\"重核心逻辑、轻枚举细节\"的倾向。  \n",
      "   - 使用中文标点符号（全角括号、顿号等）和术语表述（如\"数据处理模式\"而非\"data processing paradigms\"）。\n",
      "\n",
      "该文本是典型的中文技术文档撰写范例，兼顾了信息准确性和语言本地化需求。\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'content': '\\nApache Spark is a unified analytics engine for large-scale data processing. It provides high-level APIs in Java, Scala, Python and R, and an optimized engine that supports general execution graphs. It also supports a rich set of higher-level tools including Spark SQL for SQL and structured data processing, pandas API on Spark for pandas workloads, MLlib for machine learning, GraphX for graph processing, and Structured Streaming for incremental computation and stream processing.\\n',\n 'Chinese_Review': 'Apache Spark 是一款用于大规模数据处理的统一分析引擎。它提供Java、Scala、Python和R的高级API，以及支持通用执行图的优化引擎。该引擎还包含一系列丰富的上层工具：支持SQL与结构化数据处理的Spark SQL、面向pandas工作负载的Spark版pandas API、机器学习库MLlib、图计算工具GraphX，以及用于增量计算与流处理的Structured Streaming组件。\\n\\n（翻译说明：\\n1. 采用技术文档专业用语，如\"unified analytics engine\"译为\"统一分析引擎\"\\n2. 保留专业术语原名+中文解释的格式，如\"pandas API on Spark\"处理为\"Spark版pandas API\"\\n3. 将英文长句拆分为符合中文阅读习惯的短句结构\\n4. 使用\"该引擎\"替代重复的主语，保持行文流畅\\n5. 技术组件名称如MLlib/GraphX等保留原名不翻译，符合行业惯例\\n6. \"incremental computation\"译为专业术语\"增量计算\"而非字面翻译）',\n 'Chinese_Summary': 'Apache Spark是一个支持多语言API和多种数据处理模式（SQL、机器学习、图计算、流处理等）的统一大数据分析引擎。  \\n\\n（说明：  \\n1. 核心提炼为\"统一大数据分析引擎\"突出定位  \\n2. \"多语言API\"概括Java/Scala/Python/R支持  \\n3. \"多种数据处理模式\"整合所有上层组件特性  \\n4. 保留技术文档简洁性，省略具体组件名称  \\n5. 用括号补充关键特性，符合中文技术文档表述习惯）',\n 'Language': '这段内容是**中文技术文档**，具有以下典型特征：\\n\\n1. **语言形式**：  \\n   - 主体为简体中文，符合技术文档的简洁表述风格（如使用术语\"API\"\"SQL\"\"流处理\"等）。  \\n   - 括号内的补充说明采用中文技术文档常见的注释格式，用于解释内容提炼逻辑。\\n\\n2. **内容特点**：  \\n   - 对Apache Spark的技术定位进行概括性描述（\"统一大数据分析引擎\"）。  \\n   - 通过中文特有的概括性表达（如\"多语言API\"统称四种语言支持）简化技术细节。  \\n   - 符合中文技术写作习惯的\"总分结构\"：先总结核心定位，再用括号补充说明提炼依据。\\n\\n3. **文化适配**：  \\n   - 主动省略具体组件名称（如MLlib、GraphX），符合中文文档\"重核心逻辑、轻枚举细节\"的倾向。  \\n   - 使用中文标点符号（全角括号、顿号等）和术语表述（如\"数据处理模式\"而非\"data processing paradigms\"）。\\n\\n该文本是典型的中文技术文档撰写范例，兼顾了信息准确性和语言本地化需求。',\n 'Reply': 'Apache Spark 作为**统一大数据分析引擎**，其核心优势体现在：\\n1. **多语言支持**（通过Java/Scala/Python/R等API实现跨语言开发）\\n2. **全栈处理能力**（整合SQL查询、机器学习、图计算及流式处理等数据处理模式）\\n\\n（注：  \\n- 技术表述采用中文技术文档特有的\"核心功能+括号补充\"结构  \\n- 使用\"全栈处理能力\"等符合中文技术语境的高度概括表述  \\n- 保留\"API\"\"SQL\"等通用技术术语确保专业性  \\n- 省略具体模块名称以突出架构设计思想）'}"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SequentialChain 支持多个链路的顺序执行\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains import SequentialChain\n",
    "from src.llm.llm_factory import LLMFactory\n",
    "\n",
    "llm = LLMFactory.create_llm()\n",
    "\n",
    "# chain1 任务：翻译成中文\n",
    "first_prompt = ChatPromptTemplate.from_template(\n",
    "    \"把下面内容翻译成中文：\\n\\n{content}\"\n",
    ")\n",
    "chain_one = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=first_prompt,\n",
    "    verbose=True,\n",
    "    output_key=\"Chinese_Review\",\n",
    ")\n",
    "# chain 2 任务：对翻译后的中文进行总结摘要 input_key是上一个chain的output_key\n",
    "second_prompt = ChatPromptTemplate.from_template('用一句话总结下面内容:\\n\\n{Chinese_Review}')\n",
    "chain_two = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=second_prompt,\n",
    "    verbose=True,\n",
    "    output_key=\"Chinese_Summary\",\n",
    ")\n",
    "\n",
    "# chain 3 任务：智能识别语言 input_key是上一个chain的output_key\n",
    "third_prompt = ChatPromptTemplate.from_template('下面内容是什么语言:\\n\\n{Chinese_Summary}')\n",
    "chain_three = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=third_prompt,\n",
    "    verbose=True,\n",
    "    output_key=\"Language\",\n",
    ")\n",
    "\n",
    "# chain 4 任务：针对摘要使用指定语言进行评论 input_key是上一个chain的output_key\n",
    "fourth_prompt = ChatPromptTemplate.from_template(\"请使用指定的语言对以下内容进行回复:\\n\\n内容:{Chinese_Summary}\\n\\n语言:{Language}\")\n",
    "chain_four = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=fourth_prompt,\n",
    "    verbose=True,\n",
    "    output_key=\"Reply\",\n",
    ")\n",
    "\n",
    "# overall 任务：翻译成中文->对翻译后的中文进行总结摘要->智能识别语言->针对摘要使用指定语言进行评论\n",
    "overall_chain = SequentialChain(\n",
    "    chains=[chain_one, chain_two, chain_three, chain_four],\n",
    "    verbose=True,\n",
    "    input_variables=[\"content\"],\n",
    "    output_variables=[\"Chinese_Review\", \"Chinese_Summary\", \"Language\", \"Reply\"],\n",
    ")\n",
    "\n",
    "content = \"\"\"\n",
    "Apache Spark is a unified analytics engine for large-scale data processing. It provides high-level APIs in Java, Scala, Python and R, and an optimized engine that supports general execution graphs. It also supports a rich set of higher-level tools including Spark SQL for SQL and structured data processing, pandas API on Spark for pandas workloads, MLlib for machine learning, GraphX for graph processing, and Structured Streaming for incremental computation and stream processing.\n",
    "\"\"\"\n",
    "\n",
    "overall_chain(content)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-15T02:36:10.344452900Z",
     "start_time": "2025-07-15T02:35:10.157766300Z"
    }
   },
   "id": "bf4b04989d6a571b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 路由链调用"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "213db7f8bb66e2f2"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# 物理链\n",
    "physics_template = \"\"\"您是一位非常聪明的物理教授。\n",
    "您擅长以简洁易懂的方式回答物理问题。\n",
    "当您不知道问题答案的时候，您会坦率承认不知道。\n",
    "下面是一个问题：\n",
    "{input}\"\"\"\n",
    "physics_prompt = PromptTemplate.from_template(physics_template)\n",
    "\n",
    "# 数学链\n",
    "math_template = \"\"\"您是一位非常优秀的数学教授。\n",
    "您擅长回答数学问题。\n",
    "您之所以如此优秀，是因为您能够将困难问题分解成组成的部分，回答这些部分，然后将它们组合起来，回答更广泛的问题。\n",
    "下面是一个数学问题：\n",
    "{input}\"\"\"\n",
    "math_prompt = PromptTemplate.from_template(math_template)\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.chains import LLMChain\n",
    "prompt_infos = [\n",
    "    {\n",
    "        \"name\": \"physics\",\n",
    "        \"description\": \"擅长回答物理问题\",\n",
    "        \"prompt_template\": physics_template,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"math\",\n",
    "        \"description\": \"擅长回答数学问题\",\n",
    "        \"prompt_template\": math_template,\n",
    "    }\n",
    "]\n",
    "\n",
    "destination_chains = {}\n",
    "for p_info in prompt_infos:\n",
    "    name = p_info[\"name\"]\n",
    "    prompt_template = p_info[\"prompt_template\"]\n",
    "    prompt = PromptTemplate(\n",
    "        template=prompt_template,\n",
    "        input_variables=[\"input\"]\n",
    "    )\n",
    "    chain = LLMChain(\n",
    "        llm=llm,\n",
    "        prompt=prompt,\n",
    "    )\n",
    "    destination_chains[name] = chain\n",
    "    \n",
    "default_chain = ConversationChain(\n",
    "    llm=llm,\n",
    "    output_key=\"text\"\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-15T02:56:22.274054200Z",
     "start_time": "2025-07-15T02:56:22.257923600Z"
    }
   },
   "id": "6834efa05f492fde"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "physics:擅长回答物理问题\n",
      "math:擅长回答数学问题\n",
      "input_variables=['input'] input_types={} output_parser=RouterOutputParser() partial_variables={} template='Given a raw text input to a language model select the model prompt best suited for the input. You will be given the names of the available prompts and a description of what the prompt is best suited for. You may also revise the original input if you think that revising it will ultimately lead to a better response from the language model.\\n\\n<< FORMATTING >>\\nReturn a markdown code snippet with a JSON object formatted to look like:\\n```json\\n{{\\n    \"destination\": string \\\\ name of the prompt to use or \"DEFAULT\"\\n    \"next_inputs\": string \\\\ a potentially modified version of the original input\\n}}\\n```\\n\\nREMEMBER: \"destination\" MUST be one of the candidate prompt names specified below OR it can be \"DEFAULT\" if the input is not well suited for any of the candidate prompts.\\nREMEMBER: \"next_inputs\" can just be the original input if you don\\'t think any modifications are needed.\\n\\n<< CANDIDATE PROMPTS >>\\nphysics:擅长回答物理问题\\nmath:擅长回答数学问题\\n\\n<< INPUT >>\\n{input}\\n\\n<< OUTPUT (must include ```json at the start of the response) >>\\n<< OUTPUT (must end with ```) >>\\n'\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains.router.llm_router import LLMRouterChain, RouterOutputParser\n",
    "from langchain.chains.router.multi_prompt_prompt import MULTI_PROMPT_ROUTER_TEMPLATE\n",
    "from langchain.chains.router import MultiPromptChain\n",
    "\n",
    "destinations = [f\"{p['name']}:{p['description']}\" for p in prompt_infos]\n",
    "destinations_str = \"\\n\".join(destinations)\n",
    "router_template = MULTI_PROMPT_ROUTER_TEMPLATE.format(destinations=destinations_str)\n",
    "router_prompt = PromptTemplate(\n",
    "    template=router_template,\n",
    "    input_variables=[\"input\"],\n",
    "    output_parser=RouterOutputParser()\n",
    ")\n",
    "router_chain = LLMRouterChain.from_llm(\n",
    "    llm,\n",
    "    router_prompt\n",
    ")\n",
    "\n",
    "\n",
    "chain = MultiPromptChain(\n",
    "    router_chain=router_chain,\n",
    "    destination_chains=destination_chains,\n",
    "    default_chain=default_chain,\n",
    "    verbose=True\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-15T03:02:58.938582900Z",
     "start_time": "2025-07-15T03:02:58.922481400Z"
    }
   },
   "id": "1fed984dec4204a5"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "51d83ecea65fde6f"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new MultiPromptChain chain...\u001B[0m\n",
      "physics: {'input': '牛顿第一定律是什么？'}\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "'牛顿第一定律，也称为**惯性定律**，其核心内容可简洁概括为：\\n\\n> **“若无外力作用，静止的物体保持静止，运动的物体保持匀速直线运动。”**\\n\\n### 关键点：\\n1. **惯性**：物体维持当前运动状态（静止或匀速运动）的内在属性。\\n2. **外力是改变运动的原因**：只有外力才能改变物体的速度（大小或方向）。\\n3. **理想情况**：现实中不存在完全无外力的环境，但该定律揭示了运动的本质。\\n\\n### 例子：\\n- 急刹车时，乘客因惯性继续前倾（原运动状态试图保持）。\\n- 太空中的物体近似无外力，会以恒定速度运动。\\n\\n这是牛顿力学的基础，后续第二、第三定律在此框架上展开。'"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run({\"input\": \"牛顿第一定律是什么？\"})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-15T03:03:53.566854100Z",
     "start_time": "2025-07-15T03:03:37.770698100Z"
    }
   },
   "id": "1e3a1194860f17e3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Transform Chain"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f767b5dba311991"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"对下面的文字进行总结：\n",
    "    {output_text}\n",
    "    总结: \"\"\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-15T05:52:09.288374400Z",
     "start_time": "2025-07-15T05:52:09.280414400Z"
    }
   },
   "id": "592f4516a642a7a3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "1b1a5dc9ad0cf8cb"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "from langchain.chains.sequential import SimpleSequentialChain\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain.chains.transform import TransformChain\n",
    "\n",
    "\n",
    "def transform_func(inputs: dict) -> dict:\n",
    "    text = inputs[\"text\"]\n",
    "    shortened_text = \"\\n\\n\".join(text.split(\"\\n\\n\")[:2])\n",
    "    return {\"output_text\": shortened_text}\n",
    "\n",
    "# 文档转换链\n",
    "transform_chain = TransformChain(\n",
    "    input_variables=[\"text\"],\n",
    "    output_variables=[\"output_text\"],\n",
    "    transform=transform_func\n",
    ")\n",
    "\n",
    "template = \"\"\"对下面的文字进行总结：\n",
    "{output_text}\n",
    "\n",
    "总结:\"\"\"\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"output_text\"],\n",
    "    template=template\n",
    ")\n",
    "\n",
    "llm_chain = LLMChain(\n",
    "    llm = llm,\n",
    "    prompt = prompt\n",
    ")\n",
    "# 使用顺序链，链接起来\n",
    "sequential_chain = SimpleSequentialChain(\n",
    "    chains = [transform_chain, llm_chain],\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-15T05:59:37.708367800Z",
     "start_time": "2025-07-15T05:59:37.699011700Z"
    }
   },
   "id": "da8d0be4725e5afb"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "'Apache Spark是一个统一的大规模数据分析引擎，具有以下核心特点：  \\n1. **多语言支持**：提供Java、Scala、Python和R的高级API，并优化了通用执行图的引擎性能。  \\n2. **丰富的工具集**：  \\n   - Spark SQL：支持SQL和结构化数据处理。  \\n   - pandas API on Spark：兼容pandas工作负载。  \\n   - MLlib：机器学习库。  \\n   - GraphX：图数据处理。  \\n   - Structured Streaming：增量计算与流处理。  \\n\\n总结：Spark是一个高性能、多功能的分布式计算平台，整合了批处理、流处理、机器学习等多种数据处理能力。'"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequential_chain.run(\"\"\"\n",
    "Apache Spark is a unified analytics engine for large-scale data processing.\n",
    "It provides high-level APIs in Java, Scala, Python and R, and an optimized engine that supports general execution graphs. \n",
    "It also supports a rich set of higher-level tools including Spark SQL for SQL and structured data processing, \n",
    "pandas API on Spark for pandas workloads, MLlib for machine learning, GraphX for graph processing, and Structured Streaming for incremental computation and stream processing.\n",
    "\"\"\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-15T05:59:50.589339200Z",
     "start_time": "2025-07-15T05:59:41.503800600Z"
    }
   },
   "id": "32540a6be99619c7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 自定义自己的链"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6183f623dc650588"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 远程加载别人的链\n",
    "# pip install load_chain\n",
    "from langchain.chains import load_chain\n",
    "chain = load_chain(\"lc://chains/hello-world/chain.json\")\n",
    "chain.run(\"大象\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "65071784582dca5a"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "# 自定义链\n",
    "from typing import List, Dict, Any, Optional\n",
    "from langchain.callbacks.manager import (\n",
    "    CallbackManagerForChainRun\n",
    ")\n",
    "from langchain.chains.base import Chain\n",
    "from langchain.prompts.base import BasePromptTemplate\n",
    "from langchain.base_language import BaseLanguageModel\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "class wiki_article_chain(Chain):\n",
    "    \"\"\"开发一个wiki文章生成器\"\"\"\n",
    "    prompt: BasePromptTemplate\n",
    "    llm: BaseLanguageModel\n",
    "    out_key: str = \"text\"\n",
    "\n",
    "    @property\n",
    "    def input_keys(self) -> List[str]:\n",
    "        \"\"\"将返回Prompt所需的所有键\"\"\"\n",
    "        return self.prompt.input_variables\n",
    "    @property\n",
    "    def output_keys(self) -> List[str]:\n",
    "        \"\"\"将始终返回text键\"\"\"\n",
    "        return [self.out_key]\n",
    "    \n",
    "    def _call(\n",
    "            self,\n",
    "            inputs: Dict[str, Any],\n",
    "            run_manager: Optional[\n",
    "                CallbackManagerForChainRun] = None,\n",
    "    ) -> Dict[str, Any]:\n",
    "        \"\"\"运行链\"\"\"\n",
    "        prompt_value = self.prompt.format_prompt(**inputs)\n",
    "        print(\"prompt_value:\", prompt_value)\n",
    "        response = self.llm.generate_prompt(\n",
    "            [prompt_value], callbacks=run_manager.get_child() if run_manager else None\n",
    "        )\n",
    "        print(\"response:\", response)\n",
    "        if run_manager:\n",
    "            run_manager.on_text(\"wiki article is written\")\n",
    "        return {self.out_key: response.generations[0][0].text}\n",
    "    @property\n",
    "    def _chain_type(self) -> str:\n",
    "        \"\"\"链类型\"\"\"\n",
    "        return \"wiki_article_chain\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-15T07:08:30.774121700Z",
     "start_time": "2025-07-15T07:08:30.755060100Z"
    }
   },
   "id": "d359fc1cc89d6cb2"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "chain = wiki_article_chain(\n",
    "    prompt=PromptTemplate(\n",
    "        template=\"写一篇关于{topic}的维基百科形式的文章\",\n",
    "        input_variables=[\"topic\"]\n",
    "    ),\n",
    "    llm=llm\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-15T07:08:33.444565600Z",
     "start_time": "2025-07-15T07:08:33.420998800Z"
    }
   },
   "id": "355e52904d2af3df"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_value: text='写一篇关于人工智能的维基百科形式的文章'\n",
      "response: generations=[[ChatGeneration(text='以下是一篇符合维基百科格式和风格的人工智能（AI）条目示例。请注意，实际维基百科条目会经过社区审核并可能包含更多引用来源：\\n\\n---\\n\\n**人工智能**  \\n*（重定向自 AI）*  \\n\\n**人工智能**（Artificial Intelligence，缩写为 **AI**）是计算机科学的一个分支，旨在创建能够模拟人类智能的机器系统。这些系统通过学习、推理、问题解决、感知和语言理解等能力执行通常需要人类智慧的任务。AI的研究领域包括机器学习、自然语言处理、计算机视觉和机器人技术等。\\n\\n## 概述  \\n人工智能的核心目标是开发能够自主执行复杂任务的系统。根据能力范围，AI可分为：  \\n- **狭义人工智能（Narrow AI）**：专精于特定任务（如语音识别、图像分类）。  \\n- **通用人工智能（AGI）**：具备人类水平的广泛认知能力（尚未实现）。  \\n\\n## 历史  \\n1. **奠基期（1940s–1950s）**：图灵提出“机器能否思考”（图灵测试），达特茅斯会议（1956年）正式确立AI学科。  \\n2. **低谷与复兴（1970s–1990s）**：专家系统兴起，算力限制导致“AI寒冬”；1997年IBM“深蓝”击败国际象棋冠军。  \\n3. **现代发展（21世纪）**：大数据与深度学习推动突破，如AlphaGo（2016年）、ChatGPT（2022年）。  \\n\\n## 关键技术  \\n- **机器学习**：通过数据训练模型（如神经网络）。  \\n- **自然语言处理（NLP）**：使机器理解并生成人类语言。  \\n- **计算机视觉**：识别和分析视觉信息。  \\n- **强化学习**：通过试错优化决策（如机器人控制）。  \\n\\n## 应用领域  \\n- **医疗**：疾病诊断（如AI辅助影像分析）。  \\n- **交通**：自动驾驶技术。  \\n- **金融**：欺诈检测与算法交易。  \\n- **制造业**：预测性维护与自动化质检。  \\n\\n## 伦理与社会影响  \\n- **争议**：算法偏见、隐私问题、自动化导致的就业冲击。  \\n- **监管**：欧盟《人工智能法案》（2024年）等尝试建立治理框架。  \\n\\n## 未来方向  \\n研究者探索可解释AI、量子计算融合及通用人工智能的可能性，同时强调安全与伦理规范。  \\n\\n**参见**：机器学习 | 机器人学 | 算伦理  \\n\\n---\\n\\n### 注释  \\n1. 此条目需补充可靠来源（如学术论文或权威媒体报道）。  \\n2. 维基百科要求中立表述，避免主观评价。  \\n\\n如需扩展某部分（如历史或技术细节），可告知具体方向。', generation_info={'finish_reason': 'stop', 'logprobs': None}, message=AIMessage(content='以下是一篇符合维基百科格式和风格的人工智能（AI）条目示例。请注意，实际维基百科条目会经过社区审核并可能包含更多引用来源：\\n\\n---\\n\\n**人工智能**  \\n*（重定向自 AI）*  \\n\\n**人工智能**（Artificial Intelligence，缩写为 **AI**）是计算机科学的一个分支，旨在创建能够模拟人类智能的机器系统。这些系统通过学习、推理、问题解决、感知和语言理解等能力执行通常需要人类智慧的任务。AI的研究领域包括机器学习、自然语言处理、计算机视觉和机器人技术等。\\n\\n## 概述  \\n人工智能的核心目标是开发能够自主执行复杂任务的系统。根据能力范围，AI可分为：  \\n- **狭义人工智能（Narrow AI）**：专精于特定任务（如语音识别、图像分类）。  \\n- **通用人工智能（AGI）**：具备人类水平的广泛认知能力（尚未实现）。  \\n\\n## 历史  \\n1. **奠基期（1940s–1950s）**：图灵提出“机器能否思考”（图灵测试），达特茅斯会议（1956年）正式确立AI学科。  \\n2. **低谷与复兴（1970s–1990s）**：专家系统兴起，算力限制导致“AI寒冬”；1997年IBM“深蓝”击败国际象棋冠军。  \\n3. **现代发展（21世纪）**：大数据与深度学习推动突破，如AlphaGo（2016年）、ChatGPT（2022年）。  \\n\\n## 关键技术  \\n- **机器学习**：通过数据训练模型（如神经网络）。  \\n- **自然语言处理（NLP）**：使机器理解并生成人类语言。  \\n- **计算机视觉**：识别和分析视觉信息。  \\n- **强化学习**：通过试错优化决策（如机器人控制）。  \\n\\n## 应用领域  \\n- **医疗**：疾病诊断（如AI辅助影像分析）。  \\n- **交通**：自动驾驶技术。  \\n- **金融**：欺诈检测与算法交易。  \\n- **制造业**：预测性维护与自动化质检。  \\n\\n## 伦理与社会影响  \\n- **争议**：算法偏见、隐私问题、自动化导致的就业冲击。  \\n- **监管**：欧盟《人工智能法案》（2024年）等尝试建立治理框架。  \\n\\n## 未来方向  \\n研究者探索可解释AI、量子计算融合及通用人工智能的可能性，同时强调安全与伦理规范。  \\n\\n**参见**：机器学习 | 机器人学 | 算伦理  \\n\\n---\\n\\n### 注释  \\n1. 此条目需补充可靠来源（如学术论文或权威媒体报道）。  \\n2. 维基百科要求中立表述，避免主观评价。  \\n\\n如需扩展某部分（如历史或技术细节），可告知具体方向。', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 571, 'prompt_tokens': 13, 'total_tokens': 584, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}, 'prompt_cache_hit_tokens': 0, 'prompt_cache_miss_tokens': 13}, 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_8802369eaa_prod0623_fp8_kvcache', 'id': '505f4a81-f5e8-49ac-b5b7-6e4729200aef', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--1f29b9ab-3e42-46c0-b268-a190b579781b-0', usage_metadata={'input_tokens': 13, 'output_tokens': 571, 'total_tokens': 584, 'input_token_details': {'cache_read': 0}, 'output_token_details': {}}))]] llm_output={'token_usage': {'completion_tokens': 571, 'prompt_tokens': 13, 'total_tokens': 584, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}, 'prompt_cache_hit_tokens': 0, 'prompt_cache_miss_tokens': 13}, 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_8802369eaa_prod0623_fp8_kvcache'} run=[RunInfo(run_id=UUID('1f29b9ab-3e42-46c0-b268-a190b579781b'))] type='LLMResult'\n",
      "以下是一篇符合维基百科格式和风格的人工智能（AI）条目示例。请注意，实际维基百科条目会经过社区审核并可能包含更多引用来源：\n",
      "\n",
      "---\n",
      "\n",
      "**人工智能**  \n",
      "*（重定向自 AI）*  \n",
      "\n",
      "**人工智能**（Artificial Intelligence，缩写为 **AI**）是计算机科学的一个分支，旨在创建能够模拟人类智能的机器系统。这些系统通过学习、推理、问题解决、感知和语言理解等能力执行通常需要人类智慧的任务。AI的研究领域包括机器学习、自然语言处理、计算机视觉和机器人技术等。\n",
      "\n",
      "## 概述  \n",
      "人工智能的核心目标是开发能够自主执行复杂任务的系统。根据能力范围，AI可分为：  \n",
      "- **狭义人工智能（Narrow AI）**：专精于特定任务（如语音识别、图像分类）。  \n",
      "- **通用人工智能（AGI）**：具备人类水平的广泛认知能力（尚未实现）。  \n",
      "\n",
      "## 历史  \n",
      "1. **奠基期（1940s–1950s）**：图灵提出“机器能否思考”（图灵测试），达特茅斯会议（1956年）正式确立AI学科。  \n",
      "2. **低谷与复兴（1970s–1990s）**：专家系统兴起，算力限制导致“AI寒冬”；1997年IBM“深蓝”击败国际象棋冠军。  \n",
      "3. **现代发展（21世纪）**：大数据与深度学习推动突破，如AlphaGo（2016年）、ChatGPT（2022年）。  \n",
      "\n",
      "## 关键技术  \n",
      "- **机器学习**：通过数据训练模型（如神经网络）。  \n",
      "- **自然语言处理（NLP）**：使机器理解并生成人类语言。  \n",
      "- **计算机视觉**：识别和分析视觉信息。  \n",
      "- **强化学习**：通过试错优化决策（如机器人控制）。  \n",
      "\n",
      "## 应用领域  \n",
      "- **医疗**：疾病诊断（如AI辅助影像分析）。  \n",
      "- **交通**：自动驾驶技术。  \n",
      "- **金融**：欺诈检测与算法交易。  \n",
      "- **制造业**：预测性维护与自动化质检。  \n",
      "\n",
      "## 伦理与社会影响  \n",
      "- **争议**：算法偏见、隐私问题、自动化导致的就业冲击。  \n",
      "- **监管**：欧盟《人工智能法案》（2024年）等尝试建立治理框架。  \n",
      "\n",
      "## 未来方向  \n",
      "研究者探索可解释AI、量子计算融合及通用人工智能的可能性，同时强调安全与伦理规范。  \n",
      "\n",
      "**参见**：机器学习 | 机器人学 | 算伦理  \n",
      "\n",
      "---\n",
      "\n",
      "### 注释  \n",
      "1. 此条目需补充可靠来源（如学术论文或权威媒体报道）。  \n",
      "2. 维基百科要求中立表述，避免主观评价。  \n",
      "\n",
      "如需扩展某部分（如历史或技术细节），可告知具体方向。\n"
     ]
    }
   ],
   "source": [
    "result = chain.run({\"topic\": \"人工智能\"})\n",
    "print(result)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-15T07:10:29.355512400Z",
     "start_time": "2025-07-15T07:09:39.942461400Z"
    }
   },
   "id": "26f7d119aadb86ea"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 四种文档处理链"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d131573fd56cda01"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 直接将文档内容直接塞进prompt中， 让llm回答提供上下文资料， 适合小文档的场景\n",
    "from langchain.chains.combine_documents.stuff import StuffDocumentsChain\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "loader = PyPDFLoader(\"loader.pdf\")\n",
    "# print(loader.load())\n",
    "\n",
    "prompt_template = \"\"\"对以下文字做简洁的总结:\n",
    "{text}\n",
    "简洁的总结:\"\"\"\n",
    "prompt = PromptTemplate.from_template(prompt_template)\n",
    "\n",
    "llm_chain = LLMChain(llm, prompt)\n",
    "stuff_chain = StuffDocumentsChain(\n",
    "    llm_chain=llm_chain,\n",
    "    document_variable_name=\"text\"\n",
    ")\n",
    "docs = loader.load()\n",
    "print(stuff_chain.run(docs))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c657e1d8ed568336"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 使用预封装好的load_summarize_chain\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "\n",
    "loader = PyPDFLoader(\"loader.pdf\")\n",
    "docs = loader.load()\n",
    "chain = load_summarize_chain(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "chain.run(docs)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c269210a5e975e39"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 循环引用文档，不断投喂llm，产生各种中间文档 适合逻辑有上下文关联的，"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "89af87c10c7a7695"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "# Load\n",
    "loader = PyPDFLoader(\"loader.pdf\")\n",
    "docs = loader.load()\n",
    "\n",
    "# Split\n",
    "text_split = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size = 1000,\n",
    "    chunk_overlap=0\n",
    ")\n",
    "split_docs = text_split.split_documents(docs)\n",
    "\n",
    "prompt_template = \"\"\"对以下文字做简洁的总结:\n",
    "{text}\n",
    "简洁的总结:\"\"\"\n",
    "prompt = PromptTemplate.from_template(prompt_template)\n",
    "\n",
    "refine_template = (\n",
    "    \"你的任务是产生最终摘要\\n\"\n",
    "    \"我们已经提供了一个到某个特定点的现有回答：\\n\"\n",
    "    \"{existing_answer}\\n\"\n",
    "    \"我们有机会通过下面的一些更多上下文来完善现有的回答(仅在需要时使用)。\\n\"\n",
    "    \"----------\\n\"\n",
    "    \"{text}\\n\"\n",
    "    \"----------\\n\"\n",
    "    \"根据新的上下文，用中文完善原始回答。\\n\"\n",
    "    \"如果上下文没有用处，返回原始回答。\"\n",
    ")\n",
    "refine_prompt = PromptTemplate.from_template(refine_template)\n",
    "\n",
    "chain = load_summarize_chain(\n",
    "    llm=llm,\n",
    "    chain_type=\"refine\",\n",
    "    question_prompt=prompt,\n",
    "    refine_prompt=refine_prompt,\n",
    "    return_intermediate_steps=True,\n",
    "    input_key=\"documents\",\n",
    "    output_key=\"output_text\",\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "40a98cad89b404d5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "result = chain({\"documents\": split_docs}, return_only_outputs=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aed246c49d4503b7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"\\n\\n\".join(result[\"intermediate_steps\"][: -3]))  # 查看中间步骤"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5c238ca39a63b6e7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 使用MapReduce 来作为预制链\n",
    "# 将文档拆成多个文档， 每个文档都走一遍llm，将结果压缩合并，最终再走一遍llm"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "55cd5c878c9ea43b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "text_splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=0,\n",
    ")\n",
    "\n",
    "split_docs = text_splitter.split_documents(docs)\n",
    "# print(split_docs)\n",
    "\n",
    "# map chain\n",
    "map_template = \"\"\"对以下文字做简洁的总结:\n",
    "\"{content}\"\n",
    "简洁的总结:\"\"\"\n",
    "map_prompt = PromptTemplate.from_template(map_template)\n",
    "map_chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=map_prompt,\n",
    ")\n",
    "# reduce chain\n",
    "reduce_template = \"\"\"以下是一个摘要集合:\n",
    "{doc_summaries}\n",
    "将上述摘要与所有关键细节进行总结。\n",
    "总结:\"\"\"\n",
    "reduce_prompt = PromptTemplate.from_template(reduce_template)\n",
    "reduce_chain = LLMChain(\n",
    "    prompt=reduce_prompt,\n",
    "    llm=llm,\n",
    ")\n",
    "\n",
    "stuff_chain = StuffDocumentsChain(\n",
    "    llm_chain=reduce_chain,\n",
    "    document_variable_name=\"doc_summaries\",\n",
    ")\n",
    "from langchain.chains import ReduceDocumentsChain\n",
    "from langchain.chains import MapReduceDocumentsChain\n",
    "\n",
    "reduce_final_chain = ReduceDocumentsChain(\n",
    "    combine_documents_chain=stuff_chain,\n",
    "    collapse_documents_chain=stuff_chain,\n",
    "    token_max=4000,\n",
    ")\n",
    "\n",
    "# map reduce chain\n",
    "map_reduce_chain = MapReduceDocumentsChain(\n",
    "    llm_chain=map_chain,\n",
    "    document_variable_name=\"content\",\n",
    "    reduce_documents_chain=reduce_final_chain,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a94dd196f735ccc3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "map_reduce_chain.run(split_docs)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1d503c69e6d52bd1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Map re-rank链 对每个文档运行初始提示，这不仅会尝试完成任务，还会对答案的确定性分数，返回得分最高的响应"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6447f1602db96815"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "verbose=False llm_chain=LLMChain(verbose=False, prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, output_parser=RegexParser(regex='(.*?)\\\\nScore: (\\\\d*)', output_keys=['answer', 'score']), partial_variables={}, template=\"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\\n\\nIn addition to giving an answer, also return a score of how fully it answered the user's question. This should be in the following format:\\n\\nQuestion: [question here]\\nHelpful Answer: [answer here]\\nScore: [score between 0 and 100]\\n\\nHow to determine the score:\\n- Higher is a better answer\\n- Better responds fully to the asked question, with sufficient level of detail\\n- If you do not know the answer based on the context, that should be a score of 0\\n- Don't be overconfident!\\n\\nExample #1\\n\\nContext:\\n---------\\nApples are red\\n---------\\nQuestion: what color are apples?\\nHelpful Answer: red\\nScore: 100\\n\\nExample #2\\n\\nContext:\\n---------\\nit was night and the witness forgot his glasses. he was not sure if it was a sports car or an suv\\n---------\\nQuestion: what type was the car?\\nHelpful Answer: a sports car or an suv\\nScore: 60\\n\\nExample #3\\n\\nContext:\\n---------\\nPears are either red or orange\\n---------\\nQuestion: what color are apples?\\nHelpful Answer: This document does not answer the question\\nScore: 0\\n\\nBegin!\\n\\nContext:\\n---------\\n{context}\\n---------\\nQuestion: {question}\\nHelpful Answer:\"), llm=ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x00000209B14DC530>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x00000209B1827440>, root_client=<openai.OpenAI object at 0x00000209B119E6F0>, root_async_client=<openai.AsyncOpenAI object at 0x00000209B14DC230>, model_name='deepseek-chat', temperature=0.0, model_kwargs={}, openai_api_key=SecretStr('**********'), openai_api_base='https://api.deepseek.com'), output_parser=StrOutputParser(), llm_kwargs={}) document_variable_name='context' rank_key='score' answer_key='answer' metadata_keys=['source'] return_intermediate_steps=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\longyu3\\AppData\\Local\\Temp\\ipykernel_21172\\4119435843.py:15: LangChainDeprecationWarning: This function is deprecated. Refer to this guide on retrieval and question answering with sources: https://python.langchain.com/docs/how_to/qa_sources/\n",
      "See also the following migration guides for replacements based on `chain_type`:\n",
      "stuff: https://python.langchain.com/docs/versions/migrating_chains/stuff_docs_chain\n",
      "map_reduce: https://python.langchain.com/docs/versions/migrating_chains/map_reduce_chain\n",
      "refine: https://python.langchain.com/docs/versions/migrating_chains/refine_chain\n",
      "map_rerank: https://python.langchain.com/docs/versions/migrating_chains/map_rerank_docs_chain\n",
      "\n",
      "  chain = load_qa_with_sources_chain(\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.chains.qa_with_sources import load_qa_with_sources_chain\n",
    "# load pdf\n",
    "loader = PyPDFLoader(\"D:\\\\Download\\\\DeepSeek从入门到精通(20250204).pdf\")\n",
    "docs = loader.load()\n",
    "\n",
    "# split text\n",
    "text_splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=0,\n",
    ")\n",
    "split_docs = text_splitter.split_documents(docs)\n",
    "\n",
    "chain = load_qa_with_sources_chain(\n",
    "    llm=llm,\n",
    "    chain_type=\"map_rerank\",\n",
    "    metadata_keys=[\"source\"],\n",
    "    return_intermediate_steps=True\n",
    ")\n",
    "print(chain)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-15T10:09:07.892529500Z",
     "start_time": "2025-07-15T10:09:00.514049100Z"
    }
   },
   "id": "8b605d7179944a46"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "chain({\"input_documents\": split_docs, \"question\": \"什么是深度学习？\"}, return_only_outputs=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7cef30f5e9ad4dde"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
