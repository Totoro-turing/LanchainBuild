{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 短时memory 记忆"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "from src.llm.llm_factory import LLMFactory\n",
    "\n",
    "llm = LLMFactory.create_llm()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-16T01:42:33.364134800Z",
     "start_time": "2025-07-16T01:42:28.650059400Z"
    }
   },
   "id": "db4cadc0ee6b9ae6"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\longyu3\\AppData\\Local\\Temp\\ipykernel_26328\\2725643520.py:3: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory()\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'history': 'Human: 你好，我是人类！\\nAI: 你好，我是AI，有什么可以帮助你的吗？'}"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory()\n",
    "memory.chat_memory.add_user_message(\"你好，我是人类！\")\n",
    "memory.chat_memory.add_ai_message(\"你好，我是AI，有什么可以帮助你的吗？\")\n",
    "memory.load_memory_variables({})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-16T01:34:36.198416800Z",
     "start_time": "2025-07-16T01:34:32.928171900Z"
    }
   },
   "id": "e596aa9a7e644d27"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "{'history': 'Human: 我想吃鸡肉\\nAI: 好的，我帮你找找鸡肉的做法'}"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 超过指定条数，会被删除掉\n",
    "# 实现一个最近的对话窗口，超过窗口条数的对话将被删除\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "\n",
    "memory = ConversationBufferWindowMemory(k=1)\n",
    "\n",
    "memory.save_context({\"input\":\"你好，我是人类！\"}, {\"output\":\"你好，我是AI，有什么可以帮助你的吗？\"})\n",
    "memory.save_context({\"input\":\"我想吃鸡肉\"}, {\"output\":\"好的，我帮你找找鸡肉的做法\"})\n",
    "\n",
    "memory.load_memory_variables({})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-16T01:37:34.687927500Z",
     "start_time": "2025-07-16T01:37:34.653888100Z"
    }
   },
   "id": "17c5abbe0b01136"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# 构建记忆实体概念清单, 相当于把你们的信息 剥离抽离成一个个单元实体\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.memory import ConversationEntityMemory\n",
    "memory = ConversationEntityMemory(llm=llm)\n",
    "_input = {\n",
    "    \"input\":\"胡八一和王胖子雪莉杨经常在一起冒险，合称盗墓铁三角。\"\n",
    "}\n",
    "memory.load_memory_variables(_input)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-16T01:41:38.569230800Z",
     "start_time": "2025-07-16T01:41:38.544195200Z"
    }
   },
   "id": "8a48151e398952c1"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# 使用知识图谱构建记忆模块\n",
    "from langchain.memory import ConversationKGMemory\n",
    "memory = ConversationKGMemory(llm=llm)\n",
    "memory.save_context(\n",
    "    {\"input\":\"帮我找一下tomie\"},\n",
    "    {\"output\":\"对不起请问什么是tomie？\"}\n",
    ")\n",
    "\n",
    "memory.save_context(\n",
    "    {\"input\": \"tomie是一个培训讲师\"},\n",
    "    {\"output\": \"好的，我知道了。\"}\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-16T01:55:33.602217900Z",
     "start_time": "2025-07-16T01:55:22.969825Z"
    }
   },
   "id": "5abeb93ec1c0e56c"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\longyu3\\AppData\\Local\\Temp\\ipykernel_26328\\2208959937.py:4: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationSummaryMemory(llm=llm)\n"
     ]
    }
   ],
   "source": [
    "# 长对话在内存中的处理，对对话内容进行摘要\n",
    "\n",
    "from langchain.memory import ConversationSummaryMemory\n",
    "memory = ConversationSummaryMemory(llm=llm)\n",
    "memory.save_context(\n",
    "    {\"input\":\"帮我找一下tomie\"},\n",
    "    {\"output\":\"对不起请问什么是tomie？\"}\n",
    ")\n",
    "memory.save_context(\n",
    "    {\"input\":\"tomie是一个培训讲师\"},\n",
    "    {\"output\":\"好的，我知道了。\"}\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-16T01:56:37.137731300Z",
     "start_time": "2025-07-16T01:56:25.701448Z"
    }
   },
   "id": "aff47ef77406c376"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "'The human asks the AI to help find \"tomie.\" The AI initially doesn\\'t understand what \"tomie\" is, but after the human explains that it\\'s a training instructor, the AI acknowledges the information.'"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = memory.chat_memory.messages\n",
    "# print(messages)\n",
    "memory.predict_new_summary(messages, \"\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-16T01:56:56.827198400Z",
     "start_time": "2025-07-16T01:56:48.712997800Z"
    }
   },
   "id": "a77f73c7838d5d90"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 使用chathistory 快速获得总结\n",
    "from langchain.memory import ChatMessageHistory\n",
    "\n",
    "history = ChatMessageHistory()\n",
    "history.add_user_message(\"你好，我是人类！\")\n",
    "history.add_ai_message(\"你好，我是AI小丸子，有什么可以帮助你的吗？\")\n",
    "\n",
    "memory = ConversationSummaryMemory.from_messages(\n",
    "    llm=llm,\n",
    "    chat_memory=history,\n",
    "    return_messages=True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cb7fd74267698065"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "memory.buffer"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "596b2c075ccc9f15"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 长对话进行summary\n",
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "memory = ConversationSummaryBufferMemory(\n",
    "    llm=llm,\n",
    "    max_token_limit=10,\n",
    "    return_messages=True\n",
    ")\n",
    "memory.save_context(\n",
    "    {\"input\":\"帮我找一下tomie\"},\n",
    "    {\"output\":\"对不起请问什么是tomie？\"}\n",
    ")\n",
    "memory.save_context(\n",
    "    {\"input\":\"tomie是一个培训讲师\"},\n",
    "    {\"output\":\"好的，我知道了。\"}\n",
    ")\n",
    "memory.save_context(\n",
    "    {\"input\":\"今天他要讲一门关于RAG的课程\"},\n",
    "    {\"output\":\"好的，我知道了。需要RAG的资料吗？\"}\n",
    ")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c8c96089ae83bd8a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "memory.load_memory_variables({})"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ade820aeec43c62b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Conversation Token Buffer使用token长度来决定什么时候刷新内存\n",
    "from langchain.memory import ConversationTokenBufferMemory\n",
    "from langchain.llms import OpenAI\n",
    "memory = ConversationTokenBufferMemory(\n",
    "    llm=llm,\n",
    "    max_token_limit=100  # 假设设置的最大token限制为100\n",
    ")\n",
    "memory.save_context(\n",
    "    {\"input\":\"帮我找一下tomie\"},\n",
    "    {\"output\":\"对不起请问什么是tomie？\"}\n",
    ")\n",
    "memory.save_context(\n",
    "    {\"input\":\"tomie是一个培训讲师\"},\n",
    "    {\"output\":\"好的，我知道了。\"}\n",
    ")\n",
    "memory.save_context(\n",
    "    {\"input\":\"今天他要讲一门关于RAG的课程\"},\n",
    "    {\"output\":\"好的，我知道了。需要RAG的资料吗？\"}\n",
    ")\n",
    "memory.load_memory_variables({})\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "27114471dc24bf02"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 在Chain上面使用记忆"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ec0645b160f31c27"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.prompts import PromptTemplate"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-16T02:21:24.119259700Z",
     "start_time": "2025-07-16T02:21:23.810309900Z"
    }
   },
   "id": "c636d1a18ce55a48"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 自定义模板\n",
    "template = \"\"\"你是一个可以和人类对话的机器人。\n",
    "{chat_history}\n",
    "人类:{human_input}\n",
    "机器人:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=[\"chat_history\", \"human_input\"],\n",
    ")\n",
    "\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",\n",
    ")\n",
    "chain = LLMChain(\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    prompt=prompt,\n",
    "    verbose=True,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "87a00d656f2db37b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 这里就可以循环对话，自动存储memory了\n",
    "chain.predict(human_input=\"你好，我是人类！\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e7fdd9b8eb2d6a11"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    ")\n",
    "from langchain.schema import SystemMessage, HumanMessage\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(\n",
    "            content=\"你好，我是一个可以和人类对话的机器人\",\n",
    "        ),\n",
    "        MessagesPlaceholder(\n",
    "            variable_name=\"chat_history\",\n",
    "        ),\n",
    "        HumanMessagePromptTemplate.from_template(\n",
    "            \"{human_input}\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True,\n",
    ")\n",
    "chain = LLMChain(\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    prompt=prompt,\n",
    "    verbose=True,\n",
    ")\n",
    "chain.predict(human_input=\"你好\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5cdd37c6f08d66d0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Conversation Chain 中增加记忆\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationChain\n",
    "\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key = \"history\",\n",
    "    return_messages=True\n",
    ")\n",
    "# 给对话链增加记忆\n",
    "chain = ConversationChain(\n",
    "    llm = llm,\n",
    "    memory = memory,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "chain.predict(input=\"你好，我是人类！\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2a2834cf4b569221"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 自定义一下，对其进行覆盖\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "template = \"\"\"下面是一段AI与人类的对话，AI会针对人类问题提供尽可能详细的回答，如果AI不知道答案，会直接回复'人类老爷，我真的不知道'。\n",
    "当前对话：\n",
    "{history}\n",
    "Human:{input}\n",
    "AI助手:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=[\"history\", \"input\"],\n",
    ")\n",
    "ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=ConversationBufferMemory(\n",
    "        ai_prefix = \"AI助手\",\n",
    "        return_messages=True\n",
    "    ),\n",
    "    prompt=prompt,\n",
    "    verbose=True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "77e4a1202f45cfef"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 同一个链合并使用多个记忆"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2529fcfd175677f0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.memory import (\n",
    "    ConversationBufferMemory,\n",
    "    ConversationSummaryMemory,\n",
    "    CombinedMemory\n",
    ")\n",
    "from langchain.prompts import PromptTemplate\n",
    "# 使用ConversationSummaryMemory对对话进行总结\n",
    "summary = ConversationSummaryMemory(\n",
    "    llm=llm,\n",
    "    memory_key=\"history\",\n",
    "    input_key=\"input\"\n",
    ")\n",
    "\n",
    "# 使用ConversationBufferMemory对对话进行缓存\n",
    "cov_memory = ConversationBufferMemory(\n",
    "    memory_key=\"history_now\",\n",
    "    input_key=\"input\",\n",
    ")\n",
    "combined_memory = CombinedMemory(\n",
    "    memories=[summary, cov_memory]\n",
    ")\n",
    "\n",
    "TEMPLATE = \"\"\"下面是一段AI与人类的对话，AI会针对人类问题，提供之前的对话摘要：\n",
    "{history}\n",
    "当前对话：\n",
    "{history_now}\n",
    "Human:{input}\n",
    "AI:\"\"\"\n",
    "\n",
    "PromptTemplate(\n",
    "    template=TEMPLATE,\n",
    "    input_variables=[\"history\", \"history_now\", \"input\"]\n",
    ")\n",
    "chain = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=combined_memory,\n",
    "    prompt=prompt,\n",
    "    verbose=True,\n",
    ")\n",
    "chain.run(\"你对加密货币市场怎么看\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3a1c77184b67b954"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 多参数链 增加记忆\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8f8ade2097148a4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
