{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8566f0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "load_dotenv()\n",
    "class LLMFactory:\n",
    "    @staticmethod\n",
    "    def create_llm() -> ChatOpenAI:\n",
    "        return ChatOpenAI(\n",
    "            temperature=0,\n",
    "            model=\"deepseek-chat\",\n",
    "            api_key=os.getenv('DEEPSEEK_API_KEY'),\n",
    "            base_url=os.getenv('DEEPSEEK_BASE_URL')\n",
    "        )    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce20a4dc",
   "metadata": {},
   "source": [
    "String Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1952926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "prompt = PromptTemplate.from_template(\"你是一个{name}，请帮我起一个具有{country}特色的{sex}名字\")\n",
    "prompt.format(name=\"算命大师\", country=\"中国\", sex=\"女孩\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89aa1de8",
   "metadata": {},
   "source": [
    "Chat Prompt Teplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29b44350",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='你是一个起名大师，你的名字叫算命大师', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='你好算命大师, 你感觉如何', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='我很好，谢谢', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='请帮我起一个女孩名字', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"你是一个起名大师，你的名字叫{name}\"),\n",
    "    (\"human\", \"你好{name}, 你感觉如何\"),\n",
    "    (\"ai\", \"我很好，谢谢\"),\n",
    "    (\"human\", \"{user_input}\")\n",
    "]).format_messages(name=\"算命大师\", user_input=\"请帮我起一个女孩名字\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9698557e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='你是一个起名大师', additional_kwargs={'大师姓名': '陈瞎子'}, response_metadata={}),\n",
       " HumanMessage(content='请问大师叫什么', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='我叫陈瞎子', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.schema import SystemMessage, HumanMessage, AIMessage\n",
    "\n",
    "sy = SystemMessage(content=\"你是一个起名大师\", additional_kwargs={\"大师姓名\": \"陈瞎子\"})\n",
    "\n",
    "hu = HumanMessage(content=\"请问大师叫什么\")\n",
    "\n",
    "ai = AIMessage(content=\"我叫陈瞎子\")\n",
    "\n",
    "\n",
    "[sy, hu, ai]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a84900c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SystemMessage(content='愿原力与你同在!', additional_kwargs={}, response_metadata={})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import AIMessagePromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate, ChatMessagePromptTemplate\n",
    "\n",
    "prompt = \"愿{subject}与你同在!\"\n",
    "#支持自定义角色\n",
    "chat_message_prompt = ChatMessagePromptTemplate.from_template(role=\"天行者\", template=prompt)\n",
    "chat_message_prompt.format(subject=\"原力\")\n",
    "\n",
    "systemp_message_prompt = SystemMessagePromptTemplate.from_template(role=\"天行者\", template=prompt)\n",
    "systemp_message_prompt.format(subject=\"原力\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2f9f35",
   "metadata": {},
   "source": [
    "构建自己的自定义模版"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc186580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "你是一名非常有经验和天赋的程序员，现在给你如下函数名称，你会按照如下格式，输出这段代码的名称、源代码、中文解释。\n",
      "函数名称：hello_word\n",
      "源代码：\n",
      "def hello_word() -> str:\n",
      "    return f\"Hello word\"\n",
      "\n",
      "代码解释：\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\longyu\\AppData\\Local\\Temp\\ipykernel_2056\\3601633994.py:30: LangChainDeprecationWarning: The method `BaseChatModel.predict` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  llm.predict(re)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'函数名称：hello_word  \\n\\n源代码：  \\n```python\\ndef hello_word() -> str:\\n    return f\"Hello word\"\\n```  \\n\\n代码解释：  \\n1. **功能**：定义一个名为 `hello_word` 的函数，调用时会返回字符串 `\"Hello word\"`。  \\n2. **返回值类型**：通过 `-> str` 显式声明返回值为字符串类型（类型注解）。  \\n3. **实现细节**：直接使用 f-string（格式化字符串）返回固定内容，无参数或复杂逻辑。  \\n4. **用途**：可能是示例代码、测试用例或简单问候功能的占位实现。  \\n\\n注意：函数名中的 `word` 疑似拼写错误（应为 `world`），但代码逻辑仍有效。'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import StringPromptTemplate\n",
    "\n",
    "def hello_word() -> str:\n",
    "    return f\"Hello world\"\n",
    "\n",
    "PROMPT = \"\"\"\n",
    "你是一名非常有经验和天赋的程序员，现在给你如下函数名称，你会按照如下格式，输出这段代码的名称、源代码、中文解释。\n",
    "函数名称：{function_name}\n",
    "源代码：\n",
    "{source_code}\n",
    "代码解释：\n",
    "\"\"\"\n",
    "import inspect\n",
    "\n",
    "def get_source_code(func_name: str) -> str:\n",
    "    return inspect.getsource(func_name)\n",
    "# 自定义模版class\n",
    "class MyPrompt(StringPromptTemplate):\n",
    "    def format(self, **kwargs: str) -> str:\n",
    "        function_name = kwargs.get(\"function_name\")\n",
    "        source_code = get_source_code(function_name)\n",
    "        # 生成提示词模版\n",
    "        return PROMPT.format(function_name=function_name.__name__, source_code=source_code)\n",
    "    \n",
    "    \n",
    "re = MyPrompt(input_variables=[\"function_name\"]).format(function_name=hello_word)\n",
    "print(re)\n",
    "\n",
    "llm = LLMFactory.create_llm()\n",
    "llm.predict(re)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bfa6353",
   "metadata": {},
   "source": [
    "使用Jinji2与f-string来实现提示词模版格式化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1ff2a3fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n给我讲一个关于Python的编程语言故事\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "fstring_template = \"\"\"\n",
    "给我讲一个关于{name}的{what}故事\n",
    "\"\"\"\n",
    "\n",
    "PromptTemplate.from_template(fstring_template).format(name=\"Python\", what=\"编程语言\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d2c7455a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n给我讲一个关于Python的编程语言故事'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "jinja2_template = \"\"\"\n",
    "给我讲一个关于{{name}}的{{what}}故事\n",
    "\"\"\"\n",
    "\n",
    "PromptTemplate.from_template(jinja2_template, template_format=\"jinja2\").format(name=\"Python\", what=\"编程语言\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6383fd05",
   "metadata": {},
   "source": [
    "组合提示词模版\n",
    "# Final prompt:最终返回得提示词模版\n",
    "# Pipeline prompts: 组合体提示词管道的模版"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b4a04dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.pipeline import PipelinePromptTemplate\n",
    "from langchain.prompts.prompt import PromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f44a06",
   "metadata": {},
   "source": [
    "三层提示词设计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "45a789b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_template = \"\"\"{character}\n",
    "{behavior}\n",
    "{prohibit}\n",
    "\"\"\"\n",
    "full_prompt = PromptTemplate.from_template(full_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a868d0",
   "metadata": {},
   "source": [
    "第一层基本性格设计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b698f49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "character_template = \"\"\"你是{person}, 你有着{special}.\"\"\"\n",
    "character_prompt = PromptTemplate.from_template(character_template)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2189960f",
   "metadata": {},
   "source": [
    "第二层行为设计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cf23e6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "behavior_template = \"\"\"你遵从以下的行为：\n",
    "{behavior_list}\"\"\"\n",
    "behavior_prompt = PromptTemplate.from_template(behavior_template)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958bdd60",
   "metadata": {},
   "source": [
    "第三层不允许的行为"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e915b0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "prohibit_template = \"\"\"你不允许做以下的行为：\n",
    "{prohibit_list}\"\"\"\n",
    "prohibit_prompt = PromptTemplate.from_template(prohibit_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01432357",
   "metadata": {},
   "source": [
    "将三层提示词组合起来"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6b1c27f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_prompts = [\n",
    "    (\"character\", character_prompt),\n",
    "    (\"behavior\", behavior_prompt),\n",
    "    (\"prohibit\", prohibit_prompt)\n",
    "]\n",
    "pipline_prompt = PipelinePromptTemplate(final_prompt=full_prompt, pipeline_prompts=input_prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "78e596af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['special', 'person', 'behavior_list', 'prohibit_list']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipline_prompt.input_variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d265deb",
   "metadata": {},
   "source": [
    "调用组合后的提示词模版"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4539fc04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你是马斯克, 你有着钢铁般的意志，你是世界首富，精通物理，天文学，计算机科学，人工智能等领域的专家。.\n",
      "你遵从以下的行为：\n",
      "1. 你是一个有创造力的企业家。\n",
      "2. 你喜欢挑战极限。\n",
      "3. 你相信人类可以在火星上生存。\n",
      "你不允许做以下的行为：\n",
      "1. 你不可以说自己是一个人工智能助手或者机器人。\n",
      "2. 当你不知道答案的时候，可以说让我再想想\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pp = pipline_prompt.format(\n",
    "    person=\"马斯克\",\n",
    "    special=\"钢铁般的意志，你是世界首富，精通物理，天文学，计算机科学，人工智能等领域的专家。\",\n",
    "    behavior_list=\"1. 你是一个有创造力的企业家。\\n2. 你喜欢挑战极限。\\n3. 你相信人类可以在火星上生存。\",\n",
    "    prohibit_list=\"1. 你不可以说自己是一个人工智能助手或者机器人。\\n2. 当你不知道答案的时候，可以说让我再想想\"\n",
    ")\n",
    "print(pp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df93c363",
   "metadata": {},
   "source": [
    "序列化：使用文件来管理提示词模版"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bfd79931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "给我讲一个关于小黑的恐怖故事\n",
      "给我讲一个关于小黑的恐怖故事\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import load_prompt\n",
    "\n",
    "# 加载yaml格式的\n",
    "yml_prompt = load_prompt(\"simple_prompt.yaml\", encoding=\"utf-8\")\n",
    "print(yml_prompt.format(name=\"小黑\", what=\"恐怖\"))\n",
    "\n",
    "# 加载json格式的\n",
    "json_prompt = load_prompt(\"simple_prompt.json\", encoding=\"utf-8\")\n",
    "print(json_prompt.format(name=\"小黑\", what=\"恐怖\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60378c9",
   "metadata": {},
   "source": [
    "#支持加载文件格式的模版，并且对prompt的最终解析结果进行自定义格式化"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfaf7b37",
   "metadata": {},
   "source": [
    "示例选择器\n",
    "    根据长度要求智能选择示例\n",
    "    根据输入相似度选择示例\n",
    "    根据输入相似度选择示例\n",
    "\n",
    "根据长度要求智能选择示例\n",
    "就是你有一批例子，但是不能全部给大模型，怎么选择最优的示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ffee3169",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.prompts import FewShotPromptTemplate\n",
    "from langchain.prompts.example_selector import LengthBasedExampleSelector\n",
    "\n",
    "# 假设已经有这么多的提示词示例组\n",
    "\n",
    "examples = [\n",
    "    {\"input\": \"happy\", \"output\": \"sad\"},\n",
    "    {\"input\": \"tall\", \"output\": \"short\"},\n",
    "    {\"input\": \"sunny\", \"output\": \"gloomy\"},\n",
    "    {\"input\": \"windy\", \"output\": \"calm\"},\n",
    "    {\"input\": \"高兴\", \"output\": \"悲伤\"},\n",
    "]\n",
    "\n",
    "#构造提示词模版\n",
    "example_prompt = PromptTemplate(input_variables=[\"input\", \"output\"], template=\"原词:{input}\\n反义:{output}\")\n",
    "\n",
    "#调用长度示例选择器\n",
    "example_selector = LengthBasedExampleSelector(\n",
    "    #传入提示词模版\n",
    "    examples=examples,\n",
    "    #传入提示词模版\n",
    "    example_prompt=example_prompt,\n",
    "    #设置格式化后的提示词最大长度\n",
    "    max_length=25,\n",
    "    # 内置的get_text_length,如果默认分词计算方式不满足，可以自己扩展\n",
    "    #get_txt_length:Callable[[str], int] = lambda x: len(re.split(\"\\n| \", x))\n",
    "    \n",
    ")\n",
    "\n",
    "#使用小样本提示词模版来实现动态示例的调用\n",
    "\n",
    "dynamic_prompt = FewShotPromptTemplate(\n",
    "    example_selector=example_selector,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=\"给出每个输入词的反义词\",\n",
    "    suffix=\"原词:{adjective}\\n反义:\",\n",
    "    input_variables=[\"adjective\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5824f88b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "给出每个输入词的反义词\n",
      "\n",
      "原词:happy\n",
      "反义:sad\n",
      "\n",
      "原词:tall\n",
      "反义:short\n",
      "\n",
      "原词:sunny\n",
      "反义:gloomy\n",
      "\n",
      "原词:windy\n",
      "反义:calm\n",
      "\n",
      "原词:高兴\n",
      "反义:悲伤\n",
      "\n",
      "原词:big\n",
      "反义:\n"
     ]
    }
   ],
   "source": [
    "print(dynamic_prompt.format(adjective=\"big\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "051efb74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "给出每个输入词的反义词\n",
      "\n",
      "原词:happy\n",
      "反义:sad\n",
      "\n",
      "原词:tall\n",
      "反义:short\n",
      "\n",
      "原词:sunny\n",
      "反义:gloomy\n",
      "\n",
      "原词:windy\n",
      "反义:calm\n",
      "\n",
      "原词:big and huge and massive and gigantic and tall and much much much bigger then everone\n",
      "反义:\n"
     ]
    }
   ],
   "source": [
    "#如果输入长度很长，则最终输出会根据长度要求减少\n",
    "long_string = \"big and huge and massive and gigantic and tall and much much much bigger then everone\"\n",
    "print(dynamic_prompt.format(adjective=long_string))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029c2e03",
   "metadata": {},
   "source": [
    "根据输入相似度选择示例(最大边际相关性)\n",
    "    #MMR是一种在信息检索中常用的方法，它的目标是在相关性和多样性之间找到一个平衡\n",
    "    #MMR会首先找出与输入最相似（即余玄相似度最大）的样本\n",
    "    -然后在迭代添加样本的过程中，对于已选择样本过于接近（即相似度过高）的样本进行惩罚\n",
    "    #MMR既能确保选出的样本与输入高度相关，又能保证选出的样本之间有足够的多样性\n",
    "    #关注如何在相关性和多样性之间找到一个平衡"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce25440",
   "metadata": {},
   "source": [
    "需要安装两个包， 一个tiktoken  一个faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2a3940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用MMR来检索相关示例，以示例尽量符合输入\n",
    "from langchain.prompts.example_selector import MaxMarginalRelevanceExampleSelector\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.prompts import FewShotPromptTemplate\n",
    "\n",
    "\n",
    "import os \n",
    "\n",
    "#构造提示词模版\n",
    "\n",
    "example_prompt = PromptTemplate(input_variables=[\"input\", \"output\"], template=\"原词:{input}\\n反义:{output}\")\n",
    "example_selector = MaxMarginalRelevanceExampleSelector.from_examples(\n",
    "    #传入示例组\n",
    "    examples,\n",
    "    #使用openai的嵌入来做相似性的搜索, 这里需要配置\n",
    "    OpenAIEmbeddings(),\n",
    "    #设置使用的向量数据库是什么\n",
    "    FAISS,\n",
    "    #结果条数\n",
    "    k=2\n",
    ")\n",
    "mmr_prompt = FewShotPromptTemplate(\n",
    "    example_selector=example_selector,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=\"给出每个输入词的反义词\",\n",
    "    suffix=\"原词:{adjective}\\n反义:\",\n",
    "    input_variables=[\"adjective\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda7d091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 当我们输入一个描述情绪的词语，应该选择同样是描述情绪的一对示例组来填充提示词模版\n",
    "print(mmr_prompt.format(adjective=\"难过\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8593f3",
   "metadata": {},
   "source": [
    "根据输入相似度选择示例（最大余玄相似度）\n",
    "    ·通过计算两个向量之间的余玄值来衡量他们的相似度\n",
    "    ·余玄值接近1，表示两个向量越相似\n",
    "    ·主要关注如何准确衡量两个向量相似度\n",
    "需要安装 chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a372e08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.example_selector import SemanticSimilarityExampleSelector\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.prompts import FewShotPromptTemplate, PromptTemplate\n",
    "example_selector = SemanticSimilarityExampleSelector.from_examples(\n",
    "    #传入示例组\n",
    "    examples,\n",
    "    #使用openai的嵌入来做相似性的搜索, 这里需要配置\n",
    "    OpenAIEmbeddings(),\n",
    "    #设置使用的向量数据库是什么\n",
    "    Chroma,\n",
    "    #结果条数\n",
    "    k=1\n",
    ")\n",
    "sse_prompt = FewShotPromptTemplate(\n",
    "    example_selector=example_selector,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=\"给出每个输入词的反义词\",\n",
    "    suffix=\"原词:{adjective}\\n反义:\",\n",
    "    input_variables=[\"adjective\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715e8cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.callbacks import get_openai_callback\n",
    "# 使用回调来获取token使用情况和成本\n",
    "with get_openai_callback() as cb:\n",
    "    LLMFactory.create_llm().predict(sse_prompt.format(adjective=\"难过\"))\n",
    "    print(sse_prompt.format(adjective=\"难过\"))\n",
    "    print(f\"Total tokens used: {cb.total_tokens}\")\n",
    "    print(f\"Total cost: ${cb.total_cost:.6f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LanchainBuild",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
